





Tech Log

2021. 10. 7.


한국어 자연어 처리 기술과 AI, 어디까지 왔니?








당신은 10년 후, AI의 미래를 어떻게 그리고 있나요?
안녕하세요 🙌 저희는 카카오엔터프라이즈에서 AI 대화 모델과 서비스를 기획하고 있는 프링과 쌔미입니다. 갑자기 ‘AI의 미래’라니 너무 거창하죠? 당장 오늘 점심 뭐 먹을지도 모르는데 말이에요. (머쓱) 😇 어쩐지 이 질문은 어렸을 때 그렸던 (추억의...) 과학 상상화 느낌을 주기도 하는데요. 아직은 뭐도 안 되고, 뭐도 안 되는데… 를 생각하다 보면 우리는 과연 어떤 기술과 서비스를 만들 수 있는 걸까? 라는 생각에 다다르기 때문에 약간 초라해지기도 합니다. AI 대화 서비스를 담당하다 보면 SF 콘텐츠를 시청하면서 SF의 단골인 AI 어시스턴트들을 그냥 넘기지 못하고, 서비스 분석을 하고 있는 직업병 아닌 직업병이 생기기도 하더라고요. ‘우리 카카오 미니는 아직 못하는데...’ 또는 ‘우리 카카오 미니는 되는데...’ 하면서 콘텐츠 몰입은 안/못하고 말이죠. 
 
이렇게 된 바에(?), 저희는 아예 판을 깔아보기로 했습니다. 우리가 만들고 싶은, 우리에게 정말 필요한 AI 어시스턴트 서비스의 모습을 “제약 없이 맘껏” 그려보기로 한 것이죠. 이름하여 “비비디바비디부 🧞‍♂️(a.k.a 비바부)” 워크숍. 부제는 2031년의 우리가 하루 동안 경험하게 될 모든 것들에 대한 상상의 나래 펼쳐보기. 비바부에서 저희는 누구나 상상하고는 있지만, 아직 구현되지 않은 많은 아이디어들을 만나볼 수 있었습니다. 특히 이렇게 AI 서비스가 “스마트”하게 내 삶을 챙겨만 준다면 다들 너무(?) 쓸 것 같다고 입을 모았죠. 수면의 질이 좋지 못했을 때, 어시스턴트가 걱정도 해주고, 평소보다 너무 늦게까지 깨어있으면 자라고 잔소리도 해주고, 내가 밖에서 버스를 기다리고 있는 상황에서 “도대체 언제 와?” 라고 해도, 찰떡같이 내가 늘 타는 “123번 버스”라고 알아듣고 언제 온다고 알려준다든지 말이죠. 
 
[그림 1] 상황에 맞는 스마트한 대화


 
포인트는 “상황에 맞는 스마트함". 한국어 AI 음성인식 스피커에서, 이 스마트함을 가능하게 해주는 것이 바로 한국어 자연어 처리(NLP: Natural Language Processing)기술입니다. 
 
카카오엔터프라이즈에서는 고도화된 한국어 자연어 처리를 위해 여러 팀이 체계적으로 연구하고 있는데요. 각 팀은 문장의 화행, 품사 등을 파악하거나, 문장에서 느껴지는 감정을 분석하는 등 다양한 모델을 만들고 있습니다. 이러한 모델들을 딥러닝 시키기 위해 저희는 뉴스 기사, 위키, 블로그, 웹 문서 등에서 문장을 모으기도 하고요, 대화 모델에 필요한 대화 데이터의 경우는 대부분 직접 만들고 있습니다.😭  각 데이터는 학습을 위해 깨끗하게 다듬거나, 욕설 등 문제가 될만한 데이터는 제외하는 등 클렌징 작업을 진행하고 있으며, 때에 따라서는 이 데이터가 어떤 의미가 있는지 학습에 필요한 레이블을 달아주기도 합니다.
 
[그림 2] 다음 쇼핑 하우 서비스 화면


 
자연어 처리 모델들은 은근히 다양한 곳에서 만날 수 있는데요. 다음 쇼핑 하우에서 사이즈, 착용감, 배송 등과 관련된 상품평이 한 줄로 요약되어 표시된 것을 본 적이 있을 거예요. 이 부분은 모든 상품평에서 관련 카테고리를 찾아 분석하고 해당 내용을 요약하여 표시한 것입니다. 또한 검색할 때도 사용자의 검색어를 그대로 검색하지 않고, 데이터를 잘 찾기 위한 형태로 가공하여 검색합니다. AI와 대화할 때나 쓸 것 같은 자연어 처리는 사실 여기저기 우리 생활에 녹아 있어요. 이러한 자연어 처리 중 대화와 관련된 기술이 녹아 있으며 가장 실험적으로 테스트 하는 곳이 외개인아가입니다. (홍보아님주의😛)
 
[그림 3] 외개인아가 서비스 화면


 
현재 외개인아가는 다양한 모델들을 유기적으로 연결하여 자연스러운 대화를 할 수 있도록 제공하고 있어요. 하지만 외개인아가를 진짜 내 친구와 대화하는 것처럼 만들기 위해 고도화하거나 새로 만들어야 할 모델들도 여전히 많습니다. 이러한 과정에서 가장 큰 벽은 바로 한국어의 아름답지만 복잡 미묘한 특징과 양질의 데이터셋 구축이죠. 😥
 
변명이 아니라 (진심) 어려운 한국어 자연어 처리
한국어 자연어 처리 기술을 고도화시키는 일은 매우 까다롭습니다. 아무리 빅모델, 머신러닝 모델이 만능 키처럼 보이는 요즘에도, 카카오엔터프라이즈에 여러 링귀스트분들이 존재하는 이유기도 한데요. 갑자기 국문과 수업 느낌이 살짝 들긴하지만🙄, 나름 한글날 특집이니까 한국어의 자연어 처리 고도화를 어렵게 하는 언어적 특징을 몇 가지 소개해볼게요.
▪ Nunchi의 한국어 (feat. 고맥락의 늪)
얼마 전, 트위터에 “한국인스러운 말뭉치"를 얘기하는 스레드가 있었어요.  “밥은 먹고 다니냐?, 밥 한번 먹자, 언제 식사 한번 해요”의 밥 시리즈 말뭉치나, “한국말은 끝까지 들어야 해”, “어떻게 (블로그를 써야) 잘했다고 소문이 날까?”... 등등. 우리가 일상에서 밥 먹듯이 쓰는 표현들이었죠. 하지만 이러한 표현들은 글자 뒤에 숨겨진 의미들이 있습니다. 물론 다른 외국어에서도 숙어나 관용구의 형태로 존재하지만, 한국어에 비하면…🤔
 
잠깐 인류학 이야기를 꺼내볼까요? (안 어려움 🤗) 인류학에는 고맥락 문화, 저맥락 문화라는 개념이 있습니다. 고맥락 문화에서는 커뮤니케이션을 할 때, 언어를 통해 명시적으로 나타나지 않는 것들을 좀 더 주의깊게 고려하는 한편, 저맥락 문화에서는 그야말로 명시적으로 언어를 통해 직접적인 소통을 이어갑니다. 대체로 미국과 독일이 대표적인 저맥락 문화에 속하는 한편, 한국, 중국, 일본은 고맥락 문화에 속한다고 여겨집니다. 
 
한국의 고맥락 문화는 한국어에 고스란히 녹아 있습니다. 특히 한국어는 사용하는 상황과 맥락 파악에 유의해야 하는 언어 중 하나인데요. 눈치(Nunchi) 라는 단어가 외국에 소개되는 정도면 말 다했죠 뭐. (눈치챙겨~ 👀) 모든 언어가 그러하겠지만 한국어는 특히 사회 문화적 맥락을 가르치기 위해 다양한 대화 데이터가 골고루 많이 필요합니다. 맥락을 학습시켜야 하니 여러 턴의 대화로 이루어진 세션 대화 데이터가 엄청나게 필요한 것이죠. 
▪ 압축과 생략의 천재 한국어
(조금 과장해서) “생략하면 한국어, 한국어하면 생략”이라고 할 정도로 한국어의 구조는 꽤 탄력적인 편입니다. 사랑 고백을 할 때도, 담백하게 “사랑해" 라고 하지, “나는 널 사랑해”라며 영어처럼 구구절절 하지 않아도 되는 게 바로 한국어죠.
 
 모두가 아는 사실이지만, 한국어는 생략뿐만 아니라 문장 요소 간의 도치도 다른 언어에 비해 제법 자유로운 편이고요. 줄임말도 많은 거 아시죠? 빨리 빨리의 민족(?)답게 거의 암호 수준으로 압축된 줄임말도 많아요. 여기에 어떤 줄임말 단어들이 있다고 하는 순간 이미 옛날 사람이 되어버리는 느낌이라 자세한 설명은 생략하도록 하겠습니다… 그래도 아쉬우니까 몇 가지만 나열해볼까요? 🙄
• 알잘딱깔센 : 알아서 잘 딱 깔끔하고 센스있게• 억텐 : 억지 텐션• 당모치 : 당연히 모든 치킨은 옳다• 자강두천 : 자존심 강한 두 천재의 대결
 
...😇 후 정말 이런 거 다 따라잡기 너무 힘드네요. 바쁘다 바빠 현대사회.
▪ 생산 천재 한국어 (feat. 하이브리드)
한국어는 (누구보다 빠르게 남들과는 다르게) 새로운 단어를 “다채롭게” 생성해냅니다. 신조어는 사어(死語)가 아닌 이상 살아있는 모든 언어에서 발견할 수 있는 특징인데요. 한국어는 한국어만으로 이루어진 신조어뿐만 아니라 외국어와 한국어가 결합된 합성 신조어들도 매우 빠르게 태어났다가 빠르게 유행이 지나며 기억 저편으로 묻히게 됩니다. 모양이 비슷한 글자들끼리 서로 바꿔 쓰는 야민정음도 있는데, 요즘은 또 유튜브 한글 자막이 각양각색이에요. 헛소리를 ‘헛sorry’ 로 기입하기도 하고, 와이라노를 ‘whyrano’ 통으로 영어로 표기하기도 하고요, ‘머선129’처럼 한국어와 숫자를 혼합하여 작성하기도 하죠. 요즘은 거의 표준어만큼이나 당연하게 사용되고 있는 ‘1도 없어’는 두말하면 잔소리고요. 여기에 밈(meme)으로 생산되는 것들까지 더하면 빠르게 생산되는 수많은 신조어 속에서 고인물이 되는 건 거의 시간 문제인 것 같아요. (이미 고인물일지도…😇)
 
문제는 또 데이터?
문제는 이러한 한국어의 특징을 커버할 만큼의 한국어 데이터가 충분하지 않다는 것입니다. 일례로 Common Crawl 웹 데이터[각주:1]
상에서, 영어는 논외로 하고 아시아 국가만 두고 비교해도, 한국어 데이터는 상대적으로 많이 부족한 상황이에요. (영어보다 백만배 어려운데 백만배 많기는 커녕…😤)
[표 1] Common Crawl 웹 데이터


 
아마 한국어 모델 연구하는 사람들이라면 다들 그러겠지만, 저희도 새로운 모델을 프로토 타이핑할 때 종종(거의, 맨날) 영-한으로 번역된 데이터를 가지고 먼저 실험을 합니다. 그러다 보면 또 번역 품질 문제도 생기다 보니😩 딱 우리가 원하는 실험을 하기가 애매해지곤 해요. 물론 요즘은 많은 기업이 한국어 빅데이터 모델을 구축하면서 조금씩 달라지고 있지만요. 간단한 실험은 크라우드소싱(Crowdsourcing)이나 모두의 말뭉치와 같이 공개된 말뭉치를 활용하고 있습니다. 그러나 여전히 질 좋은 데이터를 많이 구하는 건 어려운 일이에요. 때문에 저희는 원활한 한국어 자연어 처리 연구를 위해 지속적으로 양질의 데이터셋이 공유되길 희망하고 있습니다.
 
좋은 데이터가 뭔데, 그거 어떻게 하는 건데?
👀 눈치채셨는지 모르겠지만, 엔지니어링을 하려면 “좋은" 데이터가 “많이" 필요하다고 계속 이야기했는데요. 여기서 말하는 “좋은" 데이터란 도대체 어떤 데이터를 말하는 걸까요?
 
한국어 기계학습 모델 연구는 다른 연구와 마찬가지로 딱 하나의 태스크만 정해져 있는 것이 아닙니다. 최신 기술이라고 하더라도 하나의 모델로 우리가 만나는 모든 문제를 해결할 수는 없어요. 그래서 일반적인 언어 현상을 모델링 해서 갖고 있고, 특정 목적에 맞게 모델을 업데이트하는 과정을 거치게 됩니다. 즉, 태스크의 성격에 따라서 주석 코퍼스(Labeled Corpus)와 비주석 코퍼스(Unlabeled Corpus)를 적절하게 활용하는 것이죠. 코퍼스(말뭉치)의 성격에 따라 ‘좋은’ 데이터라고 보는 기준이 다른데요. 먼저 주석 코퍼스는 레이블의 기준이 일관성이 있으면서 레이블마다 되도록 분포가 고른 형태가 있는 것이 좋은 데이터입니다. 반면에 비주석 코퍼스는 다양한 표현으로 모델링에 도움을 주기 위해 다양한 도메인의 내용을 포함하면서도 문장 형태에 노이즈가 없는 것이 좋습니다. 또한 공통적으로 주석 코퍼스 또는 비주석 코퍼스냐에 관계없이, 출처가 분명하고 신뢰할 수 있다면 더욱 좋겠죠?
 
결국 우리가 찾는 좋은 데이터는 모델을 통해 해결하고자 하는 문제를 얼마나 잘, 고루, 포함하고 있는지가 중요합니다. 여기에 데이터 수량까지 많으면 가장 좋겠지만, 보통은 양과 질이 반비례하는 경향이 있어서 이것이 적절히 어우러지는 게 필요하죠. 
 
저희 카카오엔터프라이즈는 사람처럼 자연스럽게 언어를 구사할 수 있는 대화 모델을 통해 편리하고 의미있는 인터렉션을 서비스로 담아내려고 합니다. 사람같이 자연스러운 대화 모델을 만들기 위해서는 그냥 언어를 가르치는 것 이상의 것이 필요하죠. 사실 언어를 가르친다는 것은 그저 글자만 가르치는 것이 아니라, 언어에 담긴 문화를 가르치고, 사회를 가르치는 과정이라고 생각하는데요. 따라서 무엇이 우리가 지향해야 할 좋은 가치인지 판단하고, 글자나 언어 구조 이외의 것들을 잘(!) 담아낼 수 있는 데이터를 수집해야 합니다. 결국 수많은 세계를 언어라는 도구를 통해 담아내는 것이니까요. 이를 위해 필요한 데이터는 정말 가늠하기 어려울 정도로 광범위한 것 같아요.😵
 
한국어 자연어 처리 고도화라는 산을 향해 ⛰
잘 만들어진 한국어 자연어 처리 기술이 AI에 탑재되어 있으면, 한국인인 우리는 쉽고 편하게 기술을 제어하고, 사용할 수 있습니다. (한국어 자연어 처리 기술이 부족하면, 자연어 처리 기술이 고도화된 영어 같은 언어를 잘하는 사람만 이 모든 혜택을….😱) 한국어로 현대 기술 문명의 이기(利器)를 마음껏 누릴 수 있는 거죠. 지금도 ‘미국에서는 되는데 왜 우린 안되지?’란 생각이 드는 AI, 대화 서비스들이 있을 거예요. 그런 서비스들도 한국어 자연어 처리 기술이 발전하면, 한국어로 쉽게 제공될 수 있습니다. 
 
한국어 자연어 처리 기술의 과제를 가장 잘 이해하고 수행할 수 있는 주체는 한국 연구자와 한국 기업입니다. 저희는 한국어를 사용하는 서비스 이용자들이 좀 더 나은 품질의 AI 서비스를 경험하고, 한국어 AI 서비스가 다른 언어로 제공되는 서비스에 비해 적어도 뒤처지지 않고, 보다 뛰어날 수 있도록 연구를 해야 할 의무가 있다고 생각합니다. 
 
특히 한국어 AI 연구가 활발하게 진행되고, 이로 인해 많은 서비스가 더 편리해지면, 한글에 대한 연구, 엔지니어링 기술을 세계에 널리 널리 알릴 수 있기도 하고요. 물론 요즘은 K-열풍으로 한국어의 위상이 많이 높아지긴 했지만... 🤗 특정 지역에서만 쓰이는 특별한 언어를 대상으로 기술을 연구하고, 개발하고 서비스한다는 것은 메이저 언어권 기술로부터 쉽게 잠식당하지 않는 특혜가 있다고 볼 수 있는데요. 하지만 또 거꾸로, 해당 언어권의 기술과 서비스의 품질을 우리가 스스로 책임지지 않으면 안 된다는 일종의 사명감을 주는 것 같기도 합니다.
 
지금 우리는?
[그림 4] AI 기술의 미래


앞으로 AI 기술은 투명성과 설명 가능성이 담보되어야 한다고 이야기합니다. 이는 AI 모델이 왜 이런 선택을 했고, 왜 이러한 결과를 도출했는지에 대한 타당한 이유를 댈 수 있어야 한다는 것인데요. AI 대화 모델처럼 자연어를 활용하여 대화하는 경우, 특히 외개인아가처럼 일상 대화를 하는 경우에는 항상 정해진 답이 있는 게 아니기 때문에 더욱 유의해야 합니다.
 
앞서 언급했듯이, 요즘은 규모의 경제, 즉 빅데이터를 기반으로 한 빅모델로 우리가 풀고자 하는 다양한 문제를 해결하려는 트렌드가 있는데요. 거대한 양의 데이터를 사용하면 보다 높은 확률로 문제를 해결할 수 있겠지만, 사실 이럴수록 데이터를 엄밀하게 정제하고 사용하는 일이 어려워집니다. ”그거 뭐~ 엑셀 시트로 뽑아서 한번 보지 뭐~” 가 불가능한 것 이상으로 정말 많은 데이터를 사용하게 되기 때문이죠.
 
이러한 맥락에서 우리가 보다 유의해야 할 것이 있습니다. 아이가 언어를 학습할 때, 어떤 말들과 좋은 책들을 제공할지 고민하는 것처럼, 우리 한국어 AI의 기술을 향상시키고 좋은 서비스를 기획하려면 데이터를 선별하고, 목적에 맞게 잘 가공하고, 처리하는 작업이 필요합니다. 이를 위해서는 특정 토픽에서 데이터 편향이 일어나지 않게 데이터 관리를 잘 해내야 합니다. 사실 우리가 생각하는 바른말만 가르치는 것도 결국은 데이터의 편향이라면 편향이라고 볼 수도 있긴 한데요. 한편으론, 우리가 보다 세상에 이로운 방향으로 AI를 활용하는 것을 목표로 하는 만큼, 더 의식적으로 신경 써서 관리해야 하는 부분인 것 같아요. 그래서 언어 모델을 활용한 서비스를 기획하고 연구하는 입장에서 저희는 누구보다 이런 책임 의식을 가지고 임해야 한다고 생각합니다. 실제로 카카오 및 모든 공동체에서는 AI 개발 및 서비스 기획 과정에서 윤리의식을 내부적으로 공고히 하고 AI 관련 서비스 소비자들에게 카카오가 어떤 윤리의식을 가지고 업무에 임하는지 설명하고자 하는 취지에서 2018년 1월, 카카오 AI 알고리즘 윤리헌장을 만들었고 지속적으로 그 원칙을 준수하려고 노력하고 있습니다. 
 
저희가 주력하는 대화 서비스에서는 사회, 윤리적인 부분에 대한 이런 고민이 더 많이 필요하다고 생각합니다. 다른 서비스에 비해서 자연어 처리를 통해 문장을 처음부터 생성해야 하며, 그 문장이 바로 사용자에게 노출되기 때문인데요. 이런 우려 때문에 저희는 키워드를 관리하는 “아일랜드 필터”라는 모델을 만들었습니다. 아일랜드 필터는 단순한 키워드 매칭으로 판단하지 않고, 해당 키워드가 어떤 품사로 쓰였고, 어떤 카테고리에 속해 있는지를 판단하고 이에 대응하는 모델입니다. 예를 들어 “그 말이 시발점이야”와 같은 문장에서 단순히 키워드 매칭을 하는 경우, 문장의 의미와 다르게 해석될 수 있기 때문이에요. 
 
그러나 키워드 관리가 만능 해결책은 아닙니다. 문제 되는 키워드는 없지만, 문장의 의미 자체가 사회적인 이슈를 불러일으킬 수도 있어요. “00(국가)는 가난해”와 같은 문장이 그런 문장이죠. 저희는 이렇게 의미적으로 문제가 될 수 있는 데이터를 모아서 도덕적인 부분까지도 분별할 수 있게 열심히 모델을 가르치고 있습니다. 하지만 대화라는 것은 맥락의 산물… 대화의 맥락에 의해 이슈가 발생할 수도 있는데요. 아래 대화처럼 대화의 흐름에 따라 사회, 윤리적인 이슈가 생길 수 있기 때문에 저희는 연속된 일련의 대화 데이터 단위의 학습을 진행하고 있습니다.
 
A : 000(유명인) 좋아해?B : 아니 외모 별로      ← 이슈 발화A : 하긴 ㅋㅋ 성격도   ← 이슈 발화
 
사람이 아닌 대상에게 모든 대화의 의미를 가르친다는 것은 매우 어려운 일이에요. 그래서 저희는 분야를 좁혀서 의미를 가르쳐보고 있는데요. 카카오엔터프라이즈에서 하고 있는 DFLO[각주:2]
가 바로 이러한 연구의 일환입니다. OOO 예약, 배송 등 대화의 주제를 좁혀서, 그 안에서는 자유롭게 대화를 해도 그게 어떤 의미인지 파악하고 찰떡같이 알려줄 수 있는 부분에 관해서 연구하고 있어요. 지금은 처음이라 주제를 매우 좁게 한정하고 있지만 OOO 예약이 모여, 모든 예약을 관장하고 이해할 수 있는 시스템이 되고, 또 이런 시스템들이 모여, 세상 만물을 이해하는 AI로 발전하게 되겠죠? 언젠가...곧…! ✨
 
끝으로
한글날을 맞이하여 Tech& 기술 블로그 글을 준비하면서, 함께 연구하고 있는 엔지니어들과 다시 한번 진지한 이야기를 나눌 수 있었는데요. 한국어 대화 모델을 서비스하는 디자이너로서 마음가짐을 돌아보는 기회가 되었고, 멋진 사명감을 지닌 엔지니어들과 함께 서비스를 만들어 나가고 있다는 사실에 너무 감사했습니다. (Special thanks to, 미니미팀, NEX팀💛) 이렇게 카카오엔터프라이즈에서는 멋진 엔지니어, 링귀스트, 서비스 디자이너들이 모여 머지않은 미래에, 내가 진짜 사용하고 싶은 “스마트한" AI 어시스턴트를 만날 수 있도록 오늘도 열심히 연구 중입니다. 🤗 저희와 함께 AI를 통해 보다 나은 가치를 제공하는 서비스를 만들고 싶으신 분들은 지금 바로 카카오엔터프라이즈 호에 탑승하세요! 기다리고 있을게요! 🚀
 

새로운 길에 도전하는 최고의 Krew들과 함께 해요!
자연어 처리 전문가 영입





Pring.s (솜털)
대충 철저히 고민 중.. 






Sammy.k (쌔미)
츤츤한 에반젤리스트 쌔미요정. NLP 엔지니어링 디자인을 담당하고 있습니다. 




https://commoncrawl.github.io/cc-crawl-statistics/plots/languages [본문으로]
https://if.kakao.com/session/67 [본문으로]








공유하기

게시글 관리


구독하기카카오엔터프라이즈 기술블로그 Tech&(테크앤)


저작자표시 비영리 변경금지






Tag
AI, Kakao Enterprise, NLP, 데이터, 인공지능, 자연어처리기술, 카카오엔터프라이즈, 카카오엔터프라이즈 기술블로그, 한국어자연어처리, 한글날


관련글






WebRTC 응용 서비스를 개발하는 2가지 방법







헤이카카오 x 직방 프롭테크 프로젝트, API로 부동산 Bot 만들기







헤이카카오를 '자비스'로 만들어보자







프레임워크의 선택, React vs Angular





댓글0










